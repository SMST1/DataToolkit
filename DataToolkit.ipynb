{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.What is NumPy, and why is it widely used in Python?\n",
        "--\n",
        "NumPy (short for Numerical Python) is a powerful library in Python used for numerical and scientific computing. It provides support for large multi-dimensional arrays and matrices, along with a collection of high-level mathematical functions to operate on these arrays.\n",
        "\n",
        "Key reasons why NumPy is widely used in Python:\n",
        "\n",
        "  Efficient Array Operations:\n",
        "  NumPy provides a high-performance multidimensional array object called ndarray. Operations on these arrays are performed much faster than native Python lists, especially for large datasets.\n",
        "  \n",
        "  Vectorization:\n",
        "  NumPy allows you to apply operations to entire arrays or matrices without the need for explicit loops, which makes code cleaner and faster. This is known as vectorization.\n",
        "  \n",
        "  Memory Efficiency:\n",
        "  NumPy arrays consume less memory than Python lists, and they offer better performance when dealing with large datasets.\n",
        "\n",
        "\n",
        "  Mathematical and Statistical Functions:\n",
        "  NumPy comes with a wide range of mathematical functions like linear algebra operations, statistical functions, random number generation, Fourier transforms, and more, which makes it a go-to library for many scientific computations.\n",
        "\n",
        "  Interoperability:\n",
        "  NumPy arrays can be easily integrated with other libraries like SciPy, Pandas, Matplotlib, and TensorFlow, making it an essential component of the Python data science and machine learning ecosystem.\n",
        "\n",
        "  Data Manipulation:\n",
        "  NumPy supports advanced array indexing, reshaping, and slicing, which makes it very flexible for handling complex data structures.\n",
        "  \n",
        "  Cross-Platform:\n",
        "  NumPy is cross-platform and works well across different operating systems (Linux, Windows, macOS).\n",
        "\n",
        "\n",
        "2.How does broadcasting work in NumPy?\n",
        "==\n",
        "Broadcasting in NumPy is a powerful feature that allows NumPy to perform element-wise operations on arrays of different shapes and sizes without explicitly reshaping or duplicating the data. It enables efficient computation by applying operations across arrays of incompatible shapes in a way that minimizes memory usage.\n",
        "\n",
        "Broadcasting is a method for applying operations to arrays of different shapes and sizes by implicitly expanding the smaller array to match the shape of the larger array (if possible). This feature of NumPy helps you perform complex operations efficiently without needing to write additional code for reshaping arrays.\n",
        "\n",
        "3.What is a Pandas DataFrame?\n",
        "--\n",
        "A Pandas DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It is one of the core data structures in the Pandas library, widely used for data manipulation, analysis, and cleaning in Python.\n",
        "\n",
        "A DataFrame is essentially a table that is similar to a spreadsheet or SQL table, where data is organized in rows and columns. Each column can contain data of different types (e.g., integers, strings, floats), and each row represents an observation or record.\n",
        "\n",
        "4.Explain the use of the groupby() method in Pandas?\n",
        "--\n",
        "The groupby() method in Pandas is used to group data based on certain criteria or column(s) and then apply aggregation, transformation, or filtering operations on those groups. This is useful for performing operations on subsets of your data that share common characteristics, such as calculating averages, sums, or counts within each group.\n",
        "The groupby() method splits the data into groups, applies a function to each group, and then combines the results back into a single data structure.\n",
        "\n",
        "5.Why is Seaborn preferred for statistical visualizations?\n",
        "--\n",
        "Seaborn is a Python data visualization library built on top of Matplotlib, designed specifically for creating statistical visualizations.\n",
        "\n",
        "Designed for Statistical Analysis: It simplifies the process of creating statistical plots.\n",
        "High-Level API: Provides a simpler, more intuitive syntax compared to Matplotlib.\n",
        "Integration with Pandas: Works seamlessly with Pandas DataFrames, making it ideal for data analysis.\n",
        "Better Aesthetics: Automatically applies visually appealing styles and themes to plots.\n",
        "Specialized Statistical Plots: Makes it easy to create complex statistical visualizations like regression plots, heatmaps, pairwise plots, etc.\n",
        "Customizability: While Seaborn offers a high-level interface, it still provides flexibility to fine-tune plots when needed.\n",
        "\n",
        "6.What are the differences between NumPy arrays and Python lists?\n",
        "--\n",
        "NumPy arrays and Python lists are both used to store and manipulate data in Python, but they have several key differences in terms of their structure, performance, and capabilities.\n",
        "\n",
        "Python Lists: Great for general-purpose collections, where flexibility (holding different data types) and ease of use are more important than performance.\n",
        "NumPy Arrays: Best for numerical data and large datasets, offering better performance, memory efficiency, and advanced operations for mathematical, statistical, and multidimensional data handling.\n",
        "\n",
        "In summary, NumPy arrays are the preferred choice when working with numerical data, as they provide high performance and a wide range of operations tailored to scientific computing. Python lists are more general-purpose and useful for holding heterogeneous data but are less efficient for large-scale numerical computations.\n",
        "\n",
        "7.What is a heatmap, and when should it be used?\n",
        "--\n",
        "A heatmap is a data visualization that uses color to represent the values of a matrix or a table, making it easier to understand complex data by encoding the values into colors. The color intensity or hue indicates the magnitude of the data values, helping to identify patterns, correlations, and trends at a glance.\n",
        "\n",
        "Heatmaps are particularly useful when:\n",
        "\n",
        "You need to visualize large datasets in a compact form.\n",
        "You want to show relationships between multiple variables (e.g., correlations between features in a dataset).\n",
        "You need to easily identify patterns or outliers.\n",
        "You have multidimensional data that can be represented in matrix or grid format.\n",
        "You want to highlight the distribution of data over space (e.g., geographical heatmaps) or time.\n",
        "You are working with large quantities of numerical data and need a quick way to identify trends, like peaks, troughs, or clusters.\n",
        "\n",
        "8.What does the term “vectorized operation” mean in NumPy?\n",
        "--\n",
        "In NumPy, the term \"vectorized operation\" refers to the process of performing operations on entire arrays or matrices element-wise without the need for explicit loops. Instead of iterating over the elements manually (like you would in a traditional Python loop), NumPy leverages its optimized C-based implementation to perform operations efficiently and in parallel.\n",
        "\n",
        "A vectorized operation in NumPy is a way of performing operations on arrays without using explicit loops, leveraging the under-the-hood C optimizations of NumPy for speed and efficiency. It is a key concept for working with large datasets efficiently in NumPy, offering faster performance, cleaner code, and better memory management. By using vectorized operations, you can process data more efficiently and write more concise and readable code.\n",
        "\n",
        "9.How does Matplotlib differ from Plotly?\n",
        "--\n",
        "Matplotlib and Plotly are both popular Python libraries for creating visualizations, but they have key differences in terms of their capabilities, ease of use, interactivity, and the types of visualizations they specialize in.\n",
        "\n",
        "Matplotlib is best suited for static plots and high customization where interactivity is not required, making it popular for academic papers, scientific visualization, and publication-quality figures.\n",
        "Plotly is designed for creating interactive, web-friendly plots and dashboards, making it ideal for data exploration, presentations, and business intelligence tools.\n",
        "\n",
        "10.What is the significance of hierarchical indexing in Pandas?\n",
        "--\n",
        "Hierarchical indexing in Pandas (also called MultiIndex) is a powerful feature that allows you to work with multi-dimensional data in a more structured way. It enables you to have multiple levels of indexing in a DataFrame or Series, which helps to represent and organize data that has multiple dimensions or groups.\n",
        "Hierarchical indexing is a significant feature of Pandas because it allows you to work with multi-dimensional data in a more natural and efficient way. It simplifies the manipulation, aggregation, and analysis of complex datasets, making it easier to slice, dice, and reshape data. Whether you are working with time-series data, grouped data, or datasets with multiple categorical features, hierarchical indexing provides a flexible and powerful way to handle such data.\n",
        "\n",
        "11.What is the role of Seaborn’s pairplot() function?\n",
        "--\n",
        "The pairplot() function in Seaborn is a powerful tool for visualizing relationships between multiple variables in a dataset. It creates a grid of subplots that display pairwise relationships between the columns of a DataFrame, making it a great way to explore the correlations and distributions of multiple variables at once.\n",
        "\n",
        "The pairplot() function in Seaborn is an essential tool for visualizing pairwise relationships between features in a dataset. It provides a quick and intuitive way to explore data, identify correlations, detect outliers, and understand the structure of multivariate datasets. Its ability to display both scatter plots and distributions (histograms or KDEs) in a single grid makes it a go-to function during exploratory data analysis.\n",
        "\n",
        "12.What is the purpose of the describe() function in Pandas?\n",
        "--\n",
        "The describe() function in Pandas is a powerful and frequently used method that provides a summary of the statistical characteristics of a DataFrame or Series. It is particularly useful for quickly performing exploratory data analysis (EDA) and gaining insights into the distribution, central tendency, and spread of your data.\n",
        "\n",
        "Purpose of describe():\n",
        "\n",
        "The main purpose of the describe() function is to generate a summary of statistics for numeric data (by default) or other types of data, depending on the dataset. This summary includes key statistical measures such as count, mean, standard deviation, minimum, and percentiles. It helps you to quickly get an overview of your dataset’s key properties.\n",
        "\n",
        "13.Why is handling missing data important in Pandas?\n",
        "--\n",
        "Handling missing data is a crucial aspect of data cleaning and preprocessing in Pandas (and data analysis in general). Missing data can arise for various reasons, such as errors during data collection, human input mistakes, or unrecorded values. If missing values are not appropriately addressed, they can lead to biased results, incorrect analyses, or distorted conclusions.\n",
        "\n",
        "14.What are the benefits of using Plotly for data visualization?\n",
        "--\n",
        "The benefits of using Plotly for data visualization include its ability to create interactive, dynamic, and high-quality visuals, which make it ideal for exploratory data analysis, presentations, and web-based applications. With extensive support for various chart types, smooth integration with other Python libraries, and easy sharing via web platforms, Plotly is an essential tool for anyone looking to make sophisticated, interactive plots for data analysis, business intelligence, or storytelling with data.\n",
        "\n",
        "15.How does NumPy handle multidimensional arrays?\n",
        "--\n",
        "NumPy is a powerful Python library that supports multidimensional arrays, which are arrays with more than one dimension (e.g., 2D arrays, 3D arrays, etc.). These arrays are handled efficiently by NumPy, allowing users to perform complex operations with ease.\n",
        "\n",
        "N-Dimensional Array (ndarray)\n",
        "NumPy represents multidimensional arrays using the ndarray object, which stands for N-dimensional array. The ndarray is a fast, flexible container for large datasets of homogeneous data types (i.e., all elements must be of the same data type).\n",
        "An N-dimensional array can have any number of dimensions (1D, 2D, 3D, etc.), making it versatile for a wide range of applications.\n",
        "\n",
        "16.What is the role of Bokeh in data visualization?\n",
        "--\n",
        "Bokeh is a powerful, interactive data visualization library for Python that enables the creation of visually rich, interactive plots and dashboards. It is particularly useful for generating web-based visualizations that can be embedded in websites, applications, or shared with others, without requiring users to install any software.\n",
        "\n",
        "Bokeh plays a vital role in interactive and web-based data visualization, offering a wide range of features for building dynamic plots, dashboards, and applications. It is particularly well-suited for creating real-time visualizations, offering flexible and powerful controls, and providing easy integration with Python libraries like Pandas. Bokeh is an excellent choice for data scientists and analysts who need to create interactive and web-friendly visualizations with a high level of customization, all without sacrificing performance. Whether for exploratory data analysis, web apps, or interactive presentations, Bokeh provides a comprehensive solution for data visualization.\n",
        "\n",
        "17.Explain the difference between apply() and map() in Pandas?\n",
        "--\n",
        "In Pandas, both the apply() and map() functions are used to apply a function to data in Series and DataFrames. However, they are used in slightly different ways and have distinct behavior depending on the context.\n",
        "\n",
        "map() Method\n",
        "\n",
        "Purpose: The map() function is primarily used with Pandas Series to apply a function element-wise to each value in the Series.\n",
        "Use Case: It is ideal for mapping individual values or replacing values in a Series, often with a dictionary, a function, or a Series.\n",
        "Functionality: It can handle functions, dictionaries, and Series to map values in the Series directly.\n",
        "Key Points:\n",
        "\n",
        "Works only on Series (not DataFrames).\n",
        "It can be used to map values to new values based on a dict or Series.\n",
        "It’s faster than apply() for simple mappings.\n",
        "\n",
        "apply() Method\n",
        "\n",
        "Purpose: The apply() function is more flexible and can be used on both Series and DataFrames. It applies a function along either axis (rows or columns) of a DataFrame or to the elements of a Series.\n",
        "Use Case: It is more versatile than map() and can be used for a wider range of operations, including row-wise or column-wise operations on DataFrames.\n",
        "Functionality: It applies a function to each column/row (in the case of DataFrames) or to each element (in the case of Series). It’s more general-purpose and can handle more complex operations.\n",
        "Key Points:\n",
        "\n",
        "Works on both Series and DataFrames.\n",
        "The function applied can be more complex, and you can specify the axis for DataFrame operations.\n",
        "It can be slower than map() for element-wise operations because of its greater flexibility.\n",
        "\n",
        "18.What are some advanced features of NumPy?\n",
        "--\n",
        "NumPy is a powerful numerical computing library in Python that provides a wide range of features for working with arrays and matrices. Apart from its core functionality of creating and manipulating N-dimensional arrays, it offers many advanced features that make it highly efficient for numerical computations. Below are some of the advanced features of NumPy:\n",
        "\n",
        "Broadcasting\n",
        "\n",
        "Vectorization\n",
        "\n",
        "Fancy Indexing and Slicing\n",
        "\n",
        "Linear Algebra Operations\n",
        "\n",
        "Random Number Generation\n",
        "\n",
        "Universal Functions (ufuncs)\n",
        "\n",
        "Masked Arrays\n",
        "\n",
        "Memory Management with Views and Copies\n",
        "\n",
        "Optimized Broadcasting with Stride Tricks\n",
        "\n",
        "Sparse Matrices\n",
        "\n",
        "19.How does Pandas simplify time series analysis?\n",
        "--\n",
        "Pandas is an excellent tool for time series analysis due to its powerful, easy-to-use features for working with dates and times. It simplifies many of the tasks associated with time series analysis, such as date manipulation, resampling, handling missing data, shifting data, and visualization.\n",
        "\n",
        "Date and Time Handling\n",
        "Date and Time Objects: Pandas has native support for datetime objects, which allows easy conversion between strings and datetime formats using pd.to_datetime().\n",
        "DatetimeIndex: Pandas allows you to create datetime indices for Series and DataFrames. This means that time series data can be indexed using timestamps, making it easy to slice, aggregate, and analyze based on time.\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    # Create a simple time series\n",
        "    dates = pd.date_range('2023-01-01', periods=5, freq='D')\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    df = pd.DataFrame(data, index=dates, columns=['value'])\n",
        "\n",
        "    print(df)\n",
        "\n",
        "\n",
        "Pandas simplifies time series analysis by offering powerful tools for:\n",
        "\n",
        "Handling date/time data with DatetimeIndex and conversion functions.\n",
        "\n",
        "Resampling and converting time series data to different frequencies.\n",
        "\n",
        "Shifting data for calculating time-based differences and returns.\n",
        "\n",
        "Handling missing data and filling in gaps using forward/backward fill or interpolation.\n",
        "\n",
        "Rolling window functions for calculating moving averages and other metrics.\n",
        "\n",
        "Time zone handling for dealing with time series data across different regions.\n",
        "\n",
        "20.What is the role of a pivot table in Pandas?\n",
        "--\n",
        "A pivot table in Pandas is a powerful tool for data aggregation, summarization, and transformation. It allows you to reshape and group data based on specific columns, helping you to analyze and interpret complex datasets more effectively. The concept of a pivot table in Pandas is similar to pivot tables in spreadsheet software like Excel, but it is much more flexible and efficient for handling large datasets.\n",
        "\n",
        "Data Aggregation and Grouping:\n",
        "\n",
        "Pivot tables help in aggregating data based on one or more key columns. This is especially useful when you want to calculate summary statistics (like sum, average, count, etc.) for different groups in your dataset.\n",
        "You can group the data based on specific columns, and then perform aggregate operations like mean, sum, count, min, max, etc.\n",
        "\n",
        "21.Why is NumPy’s array slicing faster than Python’s list slicing?\n",
        "--\n",
        "NumPy’s array slicing is faster than Python's list slicing primarily due to how NumPy arrays are stored and handled in memory, as well as the low-level optimizations that NumPy provides for handling large datasets efficiently.\n",
        "\n",
        "Contiguous Memory: NumPy arrays are stored in contiguous memory, while Python lists are arrays of pointers to objects, leading to faster access in NumPy.\n",
        "\n",
        "Views vs Copies: NumPy slicing creates views (references to the original data) without copying, while Python lists create new copies, making NumPy faster.\n",
        "\n",
        "Vectorization: NumPy is optimized for vectorized operations, whereas Python lists need explicit loops for element-wise operations.\n",
        "\n",
        "Optimized C/Fortran: NumPy uses optimized C and Fortran backends for efficient computation, while Python lists lack these optimizations.\n",
        "\n",
        "Memory Efficiency: NumPy arrays are more memory-efficient, especially when slicing, compared to Python lists.\n",
        "\n",
        "\n",
        "22.What are some common use cases for Seaborn?\n",
        "--\n",
        "Seaborn is a powerful Python data visualization library built on top of Matplotlib that provides a high-level interface for creating attractive and informative statistical graphics. It's widely used for its ease of use, appealing aesthetics, and ability to create complex plots with minimal code.\n",
        "\n",
        "Common Use Cases for Seaborn:\n",
        "\n",
        "Exploratory Data Analysis (EDA): Visualizing distributions and relationships between variables.\n",
        "\n",
        "Correlation and Relationships: Displaying correlations, scatter plots, and pairwise relationships.\n",
        "\n",
        "Categorical Data Visualization: Creating bar plots, box plots, violin plots, and count plots.\n",
        "\n",
        "Comparing Data Across Groups: Visualizing data grouped by categories (e.g., with FacetGrid).\n",
        "\n",
        "Statistical Visualizations: Performing regression and statistical analysis on data.\n",
        "\n",
        "Time Series Analysis: Visualizing trends and patterns over time.\n",
        "\n",
        "Multivariate Data: Exploring complex relationships in multivariate datasets.\n",
        "\n",
        "Customizing Aesthetics: Enhancing the appearance of plots for presentations and publications.\n",
        "\n",
        "Confusion Matrix Visualization: Visualizing confusion matrices for machine learning models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fno8KqWNSg1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 How do you create a 2D NumPy array and calculate the sum of each row?\n",
        "\n",
        "\"\"\"\n",
        "To create a 2D NumPy array and calculate the sum of each row, you can use the following steps:\n",
        "\n",
        "Steps:\n",
        "Create the 2D NumPy array using np.array().\n",
        "Use np.sum() with the axis=1 argument to sum the values along each row (i.e., horizontally).\n",
        "Here's an example:\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create a 2D NumPy array (3x3 array as an example)\n",
        "arr = np.array([[1, 2, 3],\n",
        "                [4, 5, 6],\n",
        "                [7, 8, 9]])\n",
        "\n",
        "# Calculate the sum of each row (axis=1 means summing across columns)\n",
        "row_sums = np.sum(arr, axis=1)\n",
        "\n",
        "# Display the result\n",
        "print(\"Original 2D Array:\")\n",
        "print(arr)\n",
        "\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n"
      ],
      "metadata": {
        "id": "LHU9JSPGxZMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Write a Pandas script to find the mean of a specific column in a DataFrame.\n",
        "\n",
        "#To find the mean of a specific column in a Pandas DataFrame, you can use the mean() method. Here's a simple example script that demonstrates how to do this:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "        'Age': [24, 27, 22, 32, 29],\n",
        "        'Salary': [50000, 55000, 60000, 65000, 70000]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the mean of the 'Age' column\n",
        "mean_age = df['Age'].mean()\n",
        "\n",
        "# Display the result\n",
        "print(f\"Mean of the 'Age' column: {mean_age}\")\n",
        "\n",
        "# Alternatively, you can find the mean of any other column (e.g., 'Salary')\n",
        "mean_salary = df['Salary'].mean()\n",
        "print(f\"Mean of the 'Salary' column: {mean_salary}\")\n"
      ],
      "metadata": {
        "id": "ShGdmGPAnsZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.Create a scatter plot using Matplotlib.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for the scatter plot\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [10, 20, 25, 30, 40]\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(x, y, color='blue', marker='o')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Simple Scatter Plot')\n",
        "plt.xlabel('X Axis')\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "JnLWVlh2yFkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap.\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [5, 4, 3, 2, 1],\n",
        "        'C': [2, 3, 4, 5, 6],\n",
        "        'D': [5, 6, 7, 8, 9]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6))  # Optional: adjust the size of the heatmap\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "\n",
        "# Add title and display the plot\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "aazSOIfgyQto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Generate a bar plot using Plotly.\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Sample data for the bar plot\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'C', 'D', 'E'],\n",
        "    'Value': [10, 15, 7, 12, 20]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a bar plot\n",
        "fig = px.bar(df, x='Category', y='Value', title='Simple Bar Plot')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "nCdmD4n9yaCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Create a DataFrame and add a new column based on an existing column.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "        'Age': [24, 27, 22, 32, 29],\n",
        "        'Salary': [50000, 55000, 60000, 65000, 70000]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add a new column 'Salary_after_tax' which is 80% of the 'Salary' (assuming 20% tax deduction)\n",
        "df['Salary_after_tax'] = df['Salary'] * 0.8\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "-sf6QQdRyjxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write a program to perform element-wise multiplication of two NumPy arrays\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create two NumPy arrays\n",
        "arr1 = np.array([1, 2, 3, 4])\n",
        "arr2 = np.array([5, 6, 7, 8])\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "result = arr1 * arr2\n",
        "\n",
        "# Display the result\n",
        "print(\"Array 1:\", arr1)\n",
        "print(\"Array 2:\", arr2)\n",
        "print(\"Element-wise multiplication result:\", result)\n"
      ],
      "metadata": {
        "id": "JYTrpshDys-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Create a line plot with multiple lines using Matplotlib.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for multiple lines\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y1 = [1, 4, 9, 16, 25]\n",
        "y2 = [25, 20, 15, 10, 5]\n",
        "y3 = [1, 2, 1, 2, 1]\n",
        "\n",
        "# Create a line plot with multiple lines\n",
        "plt.plot(x, y1, label='Line 1 (y = x^2)', color='blue', marker='o')\n",
        "plt.plot(x, y2, label='Line 2 (y = 30 - x)', color='red', marker='s')\n",
        "plt.plot(x, y3, label='Line 3 (y = alternating)', color='green', marker='^')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('X Axis')\n",
        "plt.ylabel('Y Axis')\n",
        "plt.title('Line Plot with Multiple Lines')\n",
        "\n",
        "# Add a legend to differentiate the lines\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CuKWHwfiy3zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Age': [24, 27, 22, 32, 29],\n",
        "    'Salary': [50000, 55000, 60000, 65000, 70000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define a threshold for salary (e.g., 60000)\n",
        "threshold = 60000\n",
        "\n",
        "# Filter rows where the 'Salary' column value is greater than the threshold\n",
        "filtered_df = df[df['Salary'] > threshold]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "print(filtered_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "AzfAvBqNzqUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Create a histogram using Seaborn to visualize a distribution\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for the histogram\n",
        "data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5]\n",
        "\n",
        "# Create a Seaborn histogram\n",
        "sns.histplot(data, kde=False, color='blue', bins=5)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Histogram of Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Atsah_Hez3Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.  Perform matrix multiplication using NumPy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create two matrices (2D arrays)\n",
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "\n",
        "B = np.array([[5, 6],\n",
        "              [7, 8]])\n",
        "\n",
        "# Perform matrix multiplication using np.dot()\n",
        "result = np.dot(A, B)\n",
        "\n",
        "# Alternatively, you can use the @ operator for matrix multiplication\n",
        "# result = A @ B\n",
        "\n",
        "# Display the result\n",
        "print(\"Matrix A:\")\n",
        "print(A)\n",
        "print(\"\\nMatrix B:\")\n",
        "print(B)\n",
        "print(\"\\nMatrix Multiplication Result:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "bEJorGPKz_sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12.  Use Pandas to load a CSV file and display its first 5 rows.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load a CSV file (replace 'file_path.csv' with the actual path to your CSV file)\n",
        "df = pd.read_csv('file_path.csv')\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "DYswMehU0QZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.  Create a 3D scatter plot using Plotly.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Sample data for 3D scatter plot\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [5, 4, 3, 2, 1]\n",
        "z = [10, 11, 12, 13, 14]\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=x,\n",
        "    y=y,\n",
        "    z=z,\n",
        "    mode='markers',  # 'markers' for scatter plot\n",
        "    marker=dict(\n",
        "        size=12,  # Size of the points\n",
        "        color=z,  # Color based on z values\n",
        "        colorscale='Viridis',  # Color scale for the points\n",
        "        opacity=0.8  # Opacity of the points\n",
        "    )\n",
        ")])\n",
        "\n",
        "# Add labels and title\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot',\n",
        "    scene=dict(\n",
        "        xaxis_title='X Axis',\n",
        "        yaxis_title='Y Axis',\n",
        "        zaxis_title='Z Axis'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "KQ9fo90H0oUV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}